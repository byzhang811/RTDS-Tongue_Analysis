import os
import torch
import numpy as np
from torch.utils.data import DataLoader, Dataset, random_split
from torchvision import transforms
from PIL import Image
import segmentation_models_pytorch as smp

# ================= æ ¸å¿ƒé…ç½®åŒºåŸŸ =================
# 1. ä½ çš„ SCC ç»å¯¹è·¯å¾„
IMAGES_DIR = "/projectnb/vipcnns/Boyang_Clutter/Swin_CNN/segmentation_dataset_final/segment_datasets/original"
MASKS_DIR  = "/projectnb/vipcnns/Boyang_Clutter/Swin_CNN/segmentation_dataset_final/segment_datasets/mask"

# 2. è®­ç»ƒå‚æ•°
MODEL_NAME = "U-Net++ (ResNet34 Backbone)"
SAVE_NAME = "unet_plusplus_best.pth" # ä¿å­˜çš„æ¨¡å‹æ–‡ä»¶å
BATCH_SIZE = 16       # å¦‚æœçˆ†æ˜¾å­˜æ”¹æˆ 8
LR = 0.0001           # å­¦ä¹ ç‡
EPOCHS = 30           # 30 è½®è¶³å¤Ÿæ”¶æ•›
IMG_SIZE = 256        # ç»Ÿä¸€è¾“å…¥å¤§å°
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
# ==============================================

class TongueDataset(Dataset):
    def __init__(self, img_dir, mask_dir):
        self.img_dir = img_dir
        self.mask_dir = mask_dir
        
        # è¿‡æ»¤éšè—æ–‡ä»¶å¹¶æ’åºï¼Œç¡®ä¿å›¾ç‰‡å’ŒMaskä¸€ä¸€å¯¹åº”
        self.images = sorted([f for f in os.listdir(img_dir) if not f.startswith('.')])
        self.masks = sorted([f for f in os.listdir(mask_dir) if not f.startswith('.')])
        
        # ç®€å•æ£€æŸ¥
        if len(self.images) != len(self.masks):
            print(f"âš ï¸ è­¦å‘Š: å›¾ç‰‡æ•°é‡ ({len(self.images)}) ä¸ Mask æ•°é‡ ({len(self.masks)}) ä¸ä¸€è‡´ï¼")
            # æˆªæ–­åˆ°è¾ƒçŸ­çš„é•¿åº¦ï¼Œé˜²æ­¢æŠ¥é”™
            min_len = min(len(self.images), len(self.masks))
            self.images = self.images[:min_len]
            self.masks = self.masks[:min_len]

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_path = os.path.join(self.img_dir, self.images[idx])
        mask_path = os.path.join(self.mask_dir, self.masks[idx])

        # 1. è¯»å–å›¾ç‰‡ (RGB)
        image = Image.open(img_path).convert("RGB")
        # 2. è¯»å– Mask (è½¬ç°åº¦)
        mask = Image.open(mask_path).convert("L")

        # 3. é¢„å¤„ç†ï¼šç»Ÿä¸€ Resize
        # ä½¿ç”¨åŒçº¿æ€§æ’å€¼ç¼©æ”¾å›¾ç‰‡ï¼Œé‚»è¿‘æ’å€¼ç¼©æ”¾ Mask (é˜²æ­¢å¼•å…¥è™šå‡åƒç´ å€¼)
        image = image.resize((IMG_SIZE, IMG_SIZE), Image.Resampling.BILINEAR)
        mask = mask.resize((IMG_SIZE, IMG_SIZE), Image.Resampling.NEAREST)

        # 4. è½¬ Numpy å¹¶å½’ä¸€åŒ–
        image_np = np.array(image)
        mask_np = np.array(mask)

        # Mask äºŒå€¼åŒ–å¤„ç† (ç¡®ä¿èƒŒæ™¯æ˜¯0ï¼Œå‰æ™¯æ˜¯1)
        # å‡è®¾ç™½è‰²(255)æ˜¯å‰æ™¯ï¼Œæˆ–è€…éé»‘å³å‰æ™¯
        mask_np = (mask_np > 100).astype(np.float32)
        mask_np = np.expand_dims(mask_np, axis=0) # å¢åŠ é€šé“ç»´åº¦ [1, H, W]

        # 5. è½¬ Tensor
        transform = transforms.ToTensor()
        image_tensor = transform(image_np) # ä¼šè‡ªåŠ¨å½’ä¸€åŒ–åˆ° [0, 1]
        mask_tensor = torch.from_numpy(mask_np)

        return image_tensor, mask_tensor

def main():
    print(f"ğŸš€ å¯åŠ¨ SOTA åˆ†å‰²è®­ç»ƒä»»åŠ¡...")
    print(f"æ•°æ®é›†è·¯å¾„: {IMAGES_DIR}")
    print(f"æ¨¡å‹æ¶æ„: {MODEL_NAME}")

    # --- 1. å‡†å¤‡æ•°æ® ---
    full_dataset = TongueDataset(IMAGES_DIR, MASKS_DIR)
    print(f"æˆåŠŸåŠ è½½æ•°æ®: {len(full_dataset)} å¯¹")

    # 9:1 åˆ’åˆ†è®­ç»ƒéªŒè¯é›†
    train_size = int(0.9 * len(full_dataset))
    val_size = len(full_dataset) - train_size
    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])

    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)

    # --- 2. å®šä¹‰ SOTA æ¨¡å‹ (U-Net++) ---
    # ä½¿ç”¨ ResNet34 ä½œä¸ºç¼–ç å™¨ï¼ŒåŠ è½½ ImageNet é¢„è®­ç»ƒæƒé‡
    model = smp.UnetPlusPlus(
        encoder_name="resnet34",
        encoder_weights="imagenet",
        in_channels=3,
        classes=1,
        activation=None
    )
    model.to(DEVICE)

    # --- 3. ä¼˜åŒ–å™¨ä¸æŸå¤±å‡½æ•° ---
    # DiceLoss + BCE Loss ç»„åˆï¼Œæ˜¯åˆ†å‰²ä»»åŠ¡çš„æœ€ä½³æ‹æ¡£
    loss_fn = smp.losses.DiceLoss(mode="binary", from_logits=True)
    optimizer = torch.optim.AdamW(model.parameters(), lr=LR)
    
    # å­¦ä¹ ç‡è°ƒæ•´ç­–ç•¥ (CosineAnnealing)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)

    # --- 4. è®­ç»ƒå¾ªç¯ ---
    best_iou = 0.0
    
    for epoch in range(EPOCHS):
        model.train()
        train_loss = 0
        
        for i, (images, masks) in enumerate(train_loader):
            images, masks = images.to(DEVICE), masks.to(DEVICE)
            
            optimizer.zero_grad()
            logits = model(images)
            loss = loss_fn(logits, masks)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            
        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()

        # --- éªŒè¯é˜¶æ®µ ---
        model.eval()
        val_iou_score = 0
        with torch.no_grad():
            for images, masks in val_loader:
                images, masks = images.to(DEVICE), masks.to(DEVICE)
                logits = model(images)
                
                # è®¡ç®— IoU (Intersection over Union)
                pred_mask = (logits.sigmoid() > 0.5).long()
                true_mask = masks.long()
                
                # smp è‡ªå¸¦çš„ IoU è®¡ç®—å·¥å…·
                tp, fp, fn, tn = smp.metrics.get_stats(pred_mask, true_mask, mode="binary", threshold=0.5)
                iou = smp.metrics.iou_score(tp, fp, fn, tn, reduction="micro")
                val_iou_score += iou.item()

        avg_train_loss = train_loss / len(train_loader)
        avg_val_iou = val_iou_score / len(val_loader)

        print(f"Epoch {epoch+1}/{EPOCHS} | Loss: {avg_train_loss:.4f} | Val IoU: {avg_val_iou:.4f}")

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if avg_val_iou > best_iou:
            best_iou = avg_val_iou
            torch.save(model.state_dict(), SAVE_NAME)
            print(f"  ğŸŒŸ New Best Model Saved! IoU: {best_iou:.4f}")

    print("-" * 30)
    print(f"âœ… è®­ç»ƒå®Œæˆï¼æœ€ä½³ IoU: {best_iou:.4f}")
    print(f"æ¨¡å‹å·²ä¿å­˜ä¸º: {os.path.abspath(SAVE_NAME)}")
    print("ä¸‹ä¸€æ­¥ï¼šä½¿ç”¨ clean_data_with_unet.py åŠ è½½è¿™ä¸ªæ¨¡å‹æ¥æ¸…æ´—ä½ çš„åˆ†ç±»æ•°æ®ã€‚")

if __name__ == '__main__':
    main()