import os
import torch
import numpy as np
from PIL import Image
from torchvision import transforms
import segmentation_models_pytorch as smp

# ================= ä½ çš„ç»å¯¹è·¯å¾„é…ç½® =================
# 1. æºæ•°æ®è·¯å¾„ (ä½ è§£å‹å‡ºæ¥çš„é‚£ä¸ª)
source_root = "/projectnb/vipcnns/Boyang_Clutter/Swin_CNN/classification_dataset"

# 2. è¾“å‡ºè·¯å¾„ (æ¸…æ´—åçš„å¹²å‡€æ•°æ®æ”¾è¿™é‡Œ)
target_root = "/projectnb/vipcnns/Boyang_Clutter/Swin_CNN/classification_dataset_clean"

# 3. è®­ç»ƒå¥½çš„ U-Net++ æ¨¡å‹è·¯å¾„
model_path = "/projectnb/vipcnns/Boyang_Clutter/Swin_CNN/unet_plusplus_best.pth"

# 4. å‚æ•°é…ç½®
IMG_SIZE = 256   # å¿…é¡»ä¸è®­ç»ƒåˆ†å‰²æ¨¡å‹æ—¶ä¸€è‡´
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
# ==================================================

def load_model():
    print(f"Loading U-Net++ from: {model_path}")
    # å®šä¹‰æ¨¡å‹ç»“æ„ (å¿…é¡»å’Œè®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´)
    model = smp.UnetPlusPlus(
        encoder_name="resnet34",
        encoder_weights=None, 
        in_channels=3,
        classes=1,
        activation=None
    )
    # åŠ è½½æƒé‡
    state_dict = torch.load(model_path, map_location=DEVICE)
    model.load_state_dict(state_dict)
    model.to(DEVICE)
    model.eval()
    return model

def process_and_save(model, img_path, save_path):
    try:
        # 1. è¯»å–åŸå›¾
        original_img = Image.open(img_path).convert('RGB')
        w, h = original_img.size
        
        # 2. é¢„å¤„ç†
        transform = transforms.Compose([
            transforms.Resize((IMG_SIZE, IMG_SIZE)),
            transforms.ToTensor(),
        ])
        input_tensor = transform(original_img).unsqueeze(0).to(DEVICE)
        
        # 3. æ¨ç†
        with torch.no_grad():
            logits = model(input_tensor)
            mask = (logits.sigmoid() > 0.5).float()
            
        # 4. åå¤„ç† (Mask è¿˜åŸå›åŸå›¾å°ºå¯¸)
        mask_pil = transforms.ToPILImage()(mask.squeeze(0).cpu())
        mask_pil = mask_pil.resize((w, h), Image.Resampling.NEAREST)
        mask_tensor = transforms.ToTensor()(mask_pil)
        
        # åŸå›¾è½¬ Tensor
        orig_tensor = transforms.ToTensor()(original_img)
        
        # 5. æ ¸å¿ƒæ­¥éª¤ï¼šå»èƒŒæ™¯ (å¹¿æ’­ç›¸ä¹˜)
        clean_tensor = orig_tensor * mask_tensor
        
        # 6. ä¿å­˜
        clean_img = transforms.ToPILImage()(clean_tensor)
        clean_img.save(save_path)
        return True
        
    except Exception as e:
        print(f"Error processing {img_path}: {e}")
        return False

def main():
    if not os.path.exists(source_root):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æºè·¯å¾„ {source_root}")
        return
        
    # åˆ›å»ºç›®æ ‡æ ¹ç›®å½•
    os.makedirs(target_root, exist_ok=True)
    
    # åŠ è½½æ¨¡å‹
    model = load_model()
    print("âœ… æ¨¡å‹åŠ è½½å®Œæ¯•ï¼Œå¼€å§‹æ¸…æ´—...")
    
    total_count = 0
    
    # éå†æ‰€æœ‰æ–‡ä»¶å¤¹
    for root, dirs, files in os.walk(source_root):
        # è·³è¿‡éšè—æ–‡ä»¶å¤¹
        dirs[:] = [d for d in dirs if not d.startswith('.')]
        
        for file in files:
            if file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tif')):
                src_path = os.path.join(root, file)
                
                # è®¡ç®—ç›¸å¯¹è·¯å¾„ï¼Œä¿æŒç›®å½•ç»“æ„ (ä¾‹å¦‚ "1/image_01.jpg")
                rel_path = os.path.relpath(src_path, source_root)
                dst_path = os.path.join(target_root, rel_path)
                
                # ç¡®ä¿ç›®æ ‡å­æ–‡ä»¶å¤¹å­˜åœ¨
                os.makedirs(os.path.dirname(dst_path), exist_ok=True)
                
                # å¤„ç†
                if process_and_save(model, src_path, dst_path):
                    total_count += 1
                    if total_count % 100 == 0:
                        print(f"å·²æ¸…æ´— {total_count} å¼ ...")

    print("-" * 40)
    print(f"ğŸ‰ å…¨éƒ¨å®Œæˆï¼å…±æ¸…æ´— {total_count} å¼ å›¾ç‰‡ã€‚")
    print(f"å¹²å‡€æ•°æ®å·²ä¿å­˜åœ¨: {target_root}")
    print("ç°åœ¨ï¼Œé‚£é‡Œçš„å›¾ç‰‡åº”è¯¥æ˜¯ã€é»‘åº•å½©è‰²ã€‘çš„äº†ã€‚")

if __name__ == '__main__':
    main()